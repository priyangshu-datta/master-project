{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyangshu-datta/master-project/blob/main/llm_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Editable\n",
        "1. Prompt\n",
        "1. Queries\n",
        "1. Keywords\n",
        "1. Temperature\n",
        "1. Rerank ?\n",
        "1. Rerank query\n",
        "1. DMDD ID range"
      ],
      "metadata": {
        "id": "VY54300ryIZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDICGmGJhDTB"
      },
      "outputs": [],
      "source": [
        "# @title Pip statements\n",
        "%%capture\n",
        "%pip install sentence_transformers # InstructorEmbedding\n",
        "%pip install flashrank\n",
        "%pip install black[jupyter] --quiet\n",
        "%pip install nltk\n",
        "%pip install python-Levenshtein\n",
        "%pip install pydash\n",
        "%pip install icecream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_HJJ5ephXXB"
      },
      "outputs": [],
      "source": [
        "# @title Import statements\n",
        "from pprint import pprint\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "from flashrank import Ranker, RerankRequest\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import data_table\n",
        "import time\n",
        "import google.ai.generativelanguage as glm\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "from google.oauth2 import service_account\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from Levenshtein import distance, ratio\n",
        "import pydash as py_\n",
        "import pickle\n",
        "from icecream import ic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_table.enable_dataframe_formatter()"
      ],
      "metadata": {
        "id": "wlDZgdiztCIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "with open(\"./drive/MyDrive/Thesis/data//mini_modified_DMDD.json\", \"r\") as file:\n",
        "    dmdd = json.load(file)"
      ],
      "metadata": {
        "id": "uaaYCmUlzR0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b2ece3-518a-427f-974c-61c8a46ac215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mini_dmdd = {}\n",
        "\n",
        "# for _ in dmdd:\n",
        "#     mini_dmdd[_] = {}\n",
        "#     for __ in range(0,1000):\n",
        "#         mini_dmdd[_][f\"{__}\"] = dmdd[_][f\"{__}\"]"
      ],
      "metadata": {
        "id": "HT5Ypk7s_17Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text(data, dmdd_id):\n",
        "    return data[\"text\"][f\"{dmdd_id}\"]\n",
        "\n",
        "def get_true_datasets(dmdd, dmdd_id):\n",
        "    return list(dmdd[\"datasets\"][f\"{dmdd_id}\"].keys())\n",
        "\n",
        "def get_sectioned_text(data, dmdd_id):\n",
        "    sections = data[\"sections_spans\"][f\"{dmdd_id}\"]\n",
        "    for section in sections:\n",
        "        sections[section] = get_text(data, dmdd_id)[slice(*sections[section])]\n",
        "    return sections"
      ],
      "metadata": {
        "id": "cjaKQ8LJICZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.sub(r\"([A-Z][a-z]+)\\.(?: ?(\\d+) ?\\.( [A-Z]))?\", r\"\\1[dot] \\2[dot] \\3\", \"Experiments on the Human3.6M dataset show\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uNTY7Yu1i7DY",
        "outputId": "a47c19ce-b8eb-4136-c245-f1a76688125c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Experiments on the Human3.6M dataset show'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_ci = lambda x, y: py_.partial(re.sub, x, y, flags=re.IGNORECASE)\n",
        "sub_cs = lambda x, y: py_.partial(re.sub, x, y)\n",
        "emoticons = r\"\\(>\\.>\\)|\\(\\^\\.\\^ゞ\\)|\\(\\^_\\^\\)Y|:\\-\\)|;\\-@|;\\-\\^|\\(>\\.<\\)\\(\\^\\.\\^\\)|\\(\\^_\\-\\)/\\~\\~|:\\^|;\\(|\\(\\^_\\^\\)/|\\(ToT\\)|:\\-\\^|\\(\\^\\^ゞ|:\\-=|:\\-\\#|;\\-\\[|\\(>_>\\)|:\\-D|\\(>\\.<\\)|\\(\\^o\\^\\)丿|:\\-\\.|:P|\\(\\^_\\^\\)\\-☆|\\(\\^_\\^\\)w|;\\\\|:\\-o|;\\-C|;\\-S|\\(\\^_\\^\\)v|:\\-C|\\(>\\.<\\)b|\\(\\*_\\*\\)|\\(\\-_\\-;\\)|;P|;=|\\(\\^_\\-\\)b|\\(\\^o\\^\\)|:\\-P|:\\#|\\(\\*\\^\\.\\^\\*\\)|>:\\[|\\(\\^_\\-\\)/\\~|:\\$|\\(\\^ω\\^\\)|:\\-\\{|:'\\-\\(|\\(\\^_\\-\\)\\-☆|\\(\\-_\\-\\)|x\\-\\)|:\\-X|:X|\\(\\*O\\*\\)|\\(\\*\\^_\\^\\*\\)|\\(<_<\\)|\\(ーー;\\)|;\\-\\#|:\\*|;\\-P|;\\-!|:@|\\(\\^_\\-\\)Y|:/|\\(\\^_\\-\\)W|:\\-0|\\(\\~_\\~\\)|;/|:!|;\\-D|X\\-\\)|;\\-/|;\\-=|\\(@_@\\)|\\(°\\~°\\)|\\(\\^_\\^メ\\)|:'\\(|8\\-\\)|\\(°u°\\)|;\\-\\(|:\\-\\(|:\\\\|:D|;\\-\\\\|\\(>_<\\)|\\(\\^ε\\^\\)|\\(\\^_\\^\\)b|:O|\\(\\^з\\^\\)|:\\-\\&|:=|O:\\-\\)|\\(\\^\\.\\^\\)|:\\-!|;'\\-\\)|\\('\\-'\\)|\\(\\._\\.\\)|:\\-<|;O|\\(\\^人\\^\\)|\\(\\^_\\^\\)|\\(°\\-°\\)|:'\\)|;\\-\\)|\\(\\^\\-\\^\\)|;\\-\\$|\\(\\^\\-\\^\\)b|\\(,_,\\)|\\(\\^_\\-\\)w|;\\-\\&|;D|:\\-\\||\\(°_°\\)|:S|:\\-\\\\|>:D|;\\-\\{|\\(\\^\\.\\^\\)y|\\(\\^_\\-\\)d|\\(°\\.°\\)|\\(\\^_\\^\\)/\\~|:\\-\\[|:\\-/|\\(\\^_\\^\\*\\)|:\\&|;\\-<|;'\\)|:\\)|;\\)|;\\*|\\(\\^_\\-\\)|:\\-O|;'\\-\\(|:\\-S|;\\-O|:\\(|B\\-\\)|\\(\\~_\\^\\)|;@|\\(\\^\\-\\^ゝ゛\\)|\\(\\^_\\^\\)W|;\\^|;S|\\(°o°\\)|\\(\\^O\\^\\)|\\(\\*o\\*\\)|\\(>﹏<\\)|;\\||;\\&|\\(\\^_\\^\\)/\\~\\~|:\\||>:\\)|\\(\\^_\\-\\)/|:\\-\\*|0:\\-\\)|;\\$|;!|;\\-\\||;\\#|\\(\\^_\\^'\\)|:\\-\\$|:\\-@|\\(≧∇≦\\)|\\(T_T\\)|\\(\\*\\^0\\^\\*\\)|;\\-\\*\"\n",
        "abbr_to_slug_cs = {\n",
        "    r\"([A-Z][a-z]+)\\.(?: ?(\\d+) ?\\.( [A-Z]))\": r\"\\1[dot] \\2[dot] \\3\", # Fig. 6. The | Fig. 6.ctct\n",
        "    r\"([A-Z][a-z]+) ?(\\d+)\\. ?( [A-Z])\": r\"\\1 \\2[dot] \\3\",\n",
        "    r\"([A-Z][a-z]+)\\.\": r\"\\1[dot]\", # Sentence with one word that starts with captial letter.\n",
        "}\n",
        "abbr_to_slug_ci = {\n",
        "    # r\"fig\\.(?: ?(\\d+)\\.)?\": r\"[fig][dot] \\1\",\n",
        "    # r\"tab\\.(?: ?(\\d+)\\.)?\": r\"[tab][dot] \\1\",\n",
        "    r\"et\\.? al\\.\": \"[etal]\",\n",
        "    r\"vs\\.\": \"[vs]\",\n",
        "    r\"etc\\.\": \"[etc]\",\n",
        "    r\"Eq\\.\": \"[Eq]\",\n",
        "}\n",
        "slug_to_abbr = {\n",
        "    r\"\\[dot\\]\": \".\",\n",
        "    r\"\\[etc\\]\": \"etc.\",\n",
        "    r\"\\[vs\\]\": \"vs.\",\n",
        "    r\"\\[fig\\]\": \"fig\",\n",
        "    r\"\\[tab\\]\": \"tab\",\n",
        "    r\"\\[ie\\]\": \"i.e.\",\n",
        "    r\"\\[sec\\]\": \"sec.\",\n",
        "    r\"\\[eq\\]\": \"eq.\",\n",
        "    r\"\\[eg\\]\": \"e.g.\",\n",
        "    r\"\\[ellipsis\\]\": \"...\",\n",
        "    r\"\\[aka\\]\": \"a.k.a.\",\n",
        "    r\"\\[etal\\]\": \"et al.\"\n",
        "}\n",
        "general = [\n",
        "    r\"\\( *(?:[\\w& \\.,*-]+\\d{4};?)+ *\\)\", # citations (Asic et al., 1234)\n",
        "    r\" ?\\[\\d+( ?, ?\\d+)*\\]( ?,? ?\\[\\d+( ?, ?\\d+)*\\])*\", # citations [1,2]; [1]\n",
        "    r\"\\(\\d+\\)( ?, ?\\(\\d+\\))*\", # equation numbers (1), (2)\n",
        "    # r\"[αβγδεζηθικλμνξοπρστυφχψωΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡΣΤΥΦΧΨΩ]\",\n",
        "]\n",
        "sentence_splitter = py_.flow(\n",
        "    py_.deburr,\n",
        "    lambda x: py_.reduce_(\n",
        "        py_.chain(\n",
        "            re.findall(r\"\\b(?:[a-zA-Z]+\\.){1,}[a-zA-Z]\\.\", x)\n",
        "        ).apply(set)\n",
        "        .map_(lambda x: (re.sub(\"\\.\",\"\\.\",x), re.sub(\"\\.\",\"[dot]\", x)))\n",
        "        .from_pairs()\n",
        "        .value()\n",
        "        .items(), lambda p, c: re.sub(c[0],c[1], p), x), # a.k.a. i.i.d. e.g. i.e.\n",
        "    *py_.map_(general, lambda x: sub_ci(x, \"\")),\n",
        "    sub_ci(emoticons, \"\"),\n",
        "    sub_ci(r\",\\. ([A-Z0-9])\", r\". \\1\"), # cwercwer,. The -> cwercwer. The\n",
        "    sub_ci(r\",\\. ?([a-z0-9])\", r\", \\1\"), # cwercwer,. cewrc -> cwercwer, cwerc\n",
        "    sub_ci(r\"(\\w+)@(\\w+)\\.(\\w+)\", r\"\\1@\\2[dot]\"),\n",
        "    sub_ci(r\"[\\\"'] *(.*)([\\.\\!\\?]) *[\\\"']\", r'\"\\1\\\"\\2'),\n",
        "    sub_ci(r\" *([\\.,:])\", r\"\\1\"),\n",
        "    sub_ci(r\"\\.{3}\", \"[ellipsis]\"),\n",
        "    sub_ci(r\"\\.{2}\", \".\"),\n",
        "    sub_ci(r\"\\.{4,}\", \"\"),\n",
        "    sub_ci(r\"(?:, ?){2,}\", \"\"),\n",
        "    sub_ci(r\" \\)\", \")\"),\n",
        "    sub_ci(r\"\\( \", \"(\"),\n",
        "    sub_ci(r\"([^ \\(\\.,])\\(\", r\"\\1 (\"),\n",
        "    sub_ci(r\"\\)([^ \\)\\.,:])\", r\") \\1\"),\n",
        "    sub_ci(r\"\\/{2,} \", \"\"),\n",
        "    sub_ci(r\"(\\d+)(?:\\.(\\d+))+\", r\"\\1[dot]\\2\"),\n",
        "    *py_.map_(abbr_to_slug_cs.items(), lambda x: sub_cs(x[0], x[1])),\n",
        "    *py_.map_(abbr_to_slug_ci.items(), lambda x: sub_ci(x[0], x[1])),\n",
        "    sub_ci(r\"(?:\\[dot] ){2,}\", \"[dot]\"),\n",
        "    sub_ci(\n",
        "        r\"arXiv:(\\d+)\\.(\\w+) ?(?:\\[(\\w+)\\.(\\w+)\\])?\", r\"arXiv:\\1[dot]\\2 [\\3[dot]\\4]\"\n",
        "    ),\n",
        "    sub_ci(r\"\\(([^\\)]*?)\\.([^\\)]*?)\\)\", r\"(\\1[dot]\\2)\"),\n",
        "    sub_ci(r\"\\[([^\\]]*?)\\.([^\\]]*?)\\]\", r\"[\\1[dot]\\2]\"),\n",
        "    sub_ci(r\"\\{([^\\}]*?)\\.([^\\}]*?)\\}\", r\"{\\1[dot]\\2}\"),\n",
        "    sub_ci(r\"\\b\\d+(\\.\\d+)*\", lambda match: match.group(0).replace(\".\", \"[dot]\")),\n",
        "    py_.strings.clean,\n",
        "    py_.partial(re.findall, r\"[^\\.\\!\\?]*[\\.\\!\\?]\"),\n",
        "    py_.partial(py_.reject, predicate=lambda x: len(x.split(\" \")) < 4),\n",
        "    *py_.map_(\n",
        "        slug_to_abbr.items(), lambda x: lambda y: py_.map_(y, sub_ci(x[0], x[1]))\n",
        "    ),\n",
        "    lambda x: py_.map_(x, lambda y: py_.strings.trim(y)),\n",
        ")\n",
        "\n",
        "def group_sentences(sentences, max_tokens=100, overlap=1):\n",
        "    chunks = []\n",
        "    tokens_amount = 0\n",
        "    chunk = []\n",
        "    for sentence in sentences:\n",
        "        if tokens_amount < max_tokens:\n",
        "            chunk.append(sentence)\n",
        "            tokens_amount += len(py_.strings.words(sentence))\n",
        "        else:\n",
        "            chunks.append(chunk)\n",
        "            chunk = chunk[len(chunk) - overlap :] + [sentence]\n",
        "            tokens_amount = py_.reduce_(chunk, lambda total, sentence: len(py_.strings.words(sentence)) + total, 0)\n",
        "    else:\n",
        "        chunks.append(chunk)\n",
        "\n",
        "    return py_.chain(chunks[bool(overlap) :]).map_(lambda x: \" \".join(x)).value()\n",
        "\n",
        "pretty_print_with_zeros = lambda number, length: str(number).zfill(length)"
      ],
      "metadata": {
        "id": "ZKKPwreOx5VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_rerank_model = lambda x: Ranker(\n",
        "    model_name={\n",
        "        0: \"ms-marco-TinyBERT-L-2-v2\",\n",
        "        1: \"ms-marco-MiniLM-L-12-v2\",\n",
        "        2: \"rank-T5-flan\",\n",
        "    }[x],\n",
        "    cache_dir=\"/opt\",\n",
        ")\n",
        "\n",
        "rerank_passages = py_.flow(\n",
        "    lambda model, query, passages: {\n",
        "        \"model\": model,\n",
        "        \"rerankrequest\": RerankRequest(query=query, passages=passages),\n",
        "    },\n",
        "    lambda kwargs: kwargs[\"model\"].rerank(kwargs[\"rerankrequest\"]),\n",
        "    lambda x: py_.map_(x, lambda y: y[\"text\"]),\n",
        ")"
      ],
      "metadata": {
        "id": "JyCjM-eUBvyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1aZ8loobZ4Z"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABQpcRYMshbe",
        "outputId": "8ac7d5e1-f6e0-4c30-d1ae-e0eb07c32f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WloiKvhOs-dY"
      },
      "outputs": [],
      "source": [
        "service_account_file_name = \"./drive/MyDrive/Thesis/service_account_key.json\"\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    service_account_file_name\n",
        ")\n",
        "\n",
        "scoped_credentials = credentials.with_scopes(\n",
        "    [\n",
        "        \"https://www.googleapis.com/auth/cloud-platform\",\n",
        "        \"https://www.googleapis.com/auth/generative-language.retriever\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "generative_service_client = glm.GenerativeServiceClient(credentials=scoped_credentials)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyEN1U7FQ41H"
      },
      "source": [
        "# Actual code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_grounding_passages= lambda docs: glm.GroundingPassages(passages=py_.chain(docs).map_(lambda doc: glm.Content(parts=[glm.Part(text=doc)])).map_(lambda passage, index: glm.GroundingPassage(content=passage, id=f\"{index}\")).value())"
      ],
      "metadata": {
        "id": "rhHzr32A_E5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCtjP-CP8YkR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aabdb731-3daa-4a5d-a75b-c10873b8cbdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ms-marco-TinyBERT-L-2-v2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ms-marco-TinyBERT-L-2-v2.zip: 100%|██████████| 3.26M/3.26M [00:00<00:00, 57.9MiB/s]\n"
          ]
        }
      ],
      "source": [
        "def prepare_corpus(chunks, keywords, regex=True):\n",
        "    isKeywordInChunk = lambda chunk, keyword: re.search(keyword if regex else re.escape(keyword), chunk, re.IGNORECASE)\n",
        "    isChunkUseful = lambda chunk: py_.some(keywords, py_.partial(isKeywordInChunk,chunk))\n",
        "    return py_.chain(chunks).filter_(isChunkUseful).value()\n",
        "\n",
        "def resolve_hit_documents(corpus, query_hits):\n",
        "    indices_filtered_corpus = py_.chain(query_hits).flatten().map_(lambda hit: hit[\"corpus_id\"]).map_(int).value()\n",
        "    return py_.chain(corpus).filter_(lambda _, index: index in indices_filtered_corpus).value()\n",
        "\n",
        "\n",
        "def rerank_(model_id=0):\n",
        "    rerank_model = prepare_rerank_model(model_id)\n",
        "\n",
        "    def f(docs):\n",
        "        rerank_query = \"dataset usage in retrieved documents.\"\n",
        "        docs = rerank_passages(rerank_model, rerank_query, [{\"text\": d} for d in docs])\n",
        "        return docs\n",
        "\n",
        "    return f\n",
        "\n",
        "rerank_documents = rerank_()\n",
        "\n",
        "prepare_embeddings = lambda texts: embedder.encode(texts, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZQ9MOB4eIpK"
      },
      "outputs": [],
      "source": [
        "prepare_query_content = py_.flow(\n",
        "    lambda add_to_query = \"\": \"\"\"Extract all named datasets used or mentioned in the provided passages from a research paper as it is.\n",
        "Do not change or modify the extracted dataset.\n",
        "Please ensure that the output is in csv format and that only datasets with explicit names are included from the passages.\n",
        "For clarity, a dataset refers to a collection of organized data points or records that serve a specific purpose.\n",
        "Datasets are commonly utilized in various fields such as science, research, machine learning, statistics, economics, and more.\n",
        "They can be structured or unstructured and are often referenced in research papers to support findings, validate hypotheses, or provide evidence for arguments.\n",
        "Datasets may be explicitly mentioned within the passages, such as \"We utilize the <Dataset> collected from <Source> for our analysis.\" or \"The <Dataset> provided by <Provider> contains valuable information for our research.\"\n",
        "Additionally, datasets can be constructed from other datasets through aggregation, transformation, or combination processes.\n",
        "For instance, \"We constructed our dataset by merging data from multiple sources, including <Dataset1> and <Dataset2>.\"\n",
        "In some cases, the word \"dataset\" may be implicit, and datasets may be referred to by other terms such as \"data collection\", \"data source\", or \"data repository\".\n",
        "Ensure that the extraction process accounts for variations in terminology and identifies datasets based on context and proximity to related terms.\n",
        "Do not consider datasets having \"=\" in the name.\n",
        "Ensure that the extraction process focuses on identifying datasets with specific names and excludes general descriptions of data sources or collections. Datasets are alphanumeric words that may not have any meaning.\n",
        "\"\"\" + add_to_query,\n",
        "    lambda user_query: glm.Part(text=user_query),\n",
        "    lambda part: glm.Content(parts=[part])\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "Extract named datasets from the provided passages in csv format.\n",
        "Datasets are collections of organized data points used across various fields.\n",
        "They can be mentioned explicitly or constructed from other datasets.\n",
        "Account for variations in terminology and context, but surely extract the datasets which are followed by the word \"dataset\".\n",
        "Datasets are alphanumeric words without inherent meaning.\n",
        "In cases where names may be confusingly similar, such as a dataset and a model sharing the same name, ensure that both datasets and models with similar names are extracted.\n",
        "\"\"\"\n",
        "\n",
        "generate_answer = py_.flow(\n",
        "    lambda grounded_passages, query_content, temperature=None: glm.GenerateAnswerRequest(\n",
        "        model=\"models/aqa\",\n",
        "        contents=[query_content],\n",
        "        inline_passages=grounded_passages,\n",
        "        temperature=temperature,\n",
        "        answer_style=\"EXTRACTIVE\",  # or ABSTRACTIVE, EXTRACTIVE, VERBOSE\n",
        "    ),\n",
        "    generative_service_client.generate_answer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIbnnm3pYPDi"
      },
      "outputs": [],
      "source": [
        "regex_keywords_phrases = ['data(set|base)',\n",
        "    'anal(ytics|ysis)',\n",
        "    'resear(ch|ch paper)',\n",
        "    'stud(y|ies?)',\n",
        "    'exper(iment|iments?)',\n",
        "    'method(ology|ologies?)',\n",
        "    'collect(ion|ions?)',\n",
        "    'sampl(e|ing)',\n",
        "    'variabl(e|es?)',\n",
        "    'observ(ation|ations?)',\n",
        "    'surve(y|ys?)',\n",
        "    'popul(ation|ations?)',\n",
        "    'repositor(y|ies?)',\n",
        "    'databas(e|es?)',\n",
        "    'sourc(e|es?)',\n",
        "    'raw data',\n",
        "    'secondar(y|ies?)',\n",
        "    'primar(y|ies?)',\n",
        "    'min(e|ing)',\n",
        "    'proces(s|sing)',\n",
        "    'clean(ing|)',\n",
        "    'manipul(ation|ations?)',\n",
        "    'integrat(e|ion)',\n",
        "    'aggregat(e|ion)',\n",
        "    'visualiz(e|ation)',\n",
        "    'interpret(ation|ations?)',\n",
        "    '(used|employed|utilized) for (analysis|modeling|evaluation|research)',\n",
        "    '(trained|experimented) on',\n",
        "    'analy(zed|sis) (data|dataset)',\n",
        "    '(examined|derived|investigated|explored) (data|dataset)',\n",
        "    '(employed|modeled) with (data|dataset)',\n",
        "    '(evaluated|tested|compared) on',\n",
        "    '(referenced|applied) (dataset|data)',\n",
        "    '(accessed|reviewed) (data|dataset) from',\n",
        "    \"data(-|\\s)?set\",\n",
        "    \"task\",\n",
        "    \"challenge\",\n",
        "    \"(knowledge|data)\\s*base\",\n",
        "    \"benchmark\",\n",
        "    \"(experiment|train|performance)[\\sa-zA-Z0-9]+on\",\n",
        "    \"corpus\",\n",
        "    \"class\",\n",
        "    \"(train|test)[\\sa-zA-Z0-9]+(set)?\",\n",
        "]\n",
        "\n",
        "queries = [\n",
        "    \"Data used in the study\",\n",
        "    \"Datasets employed for analysis\",\n",
        "    \"Data sources referenced\",\n",
        "    \"Dataset utilized for research\",\n",
        "    \"Data collection methods\",\n",
        "    \"Datasets examined in the paper\",\n",
        "    \"Data analysis conducted\",\n",
        "    \"Datasets referenced in the research\",\n",
        "    \"Data sources investigated\",\n",
        "    \"Dataset mentioned in the study\",\n",
        "    \"Data utilized for analysis\",\n",
        "    \"Datasets considered in the research\",\n",
        "    \"Data collection procedures\",\n",
        "    \"Dataset discussed in the paper\",\n",
        "    \"Data sources utilized\",\n",
        "    \"Datasets referenced for analysis\",\n",
        "    \"Data used for research purposes\",\n",
        "    \"Dataset examined in the study\",\n",
        "    \"Data sources referenced in the paper\",\n",
        "    \"Datasets employed for investigation\"\n",
        "]\n",
        "\n",
        "# queries = [\n",
        "    # \"datasets, database, knowledgebase\",\n",
        "    # \"experimented, trained, tested, performance on.\",\n",
        "    # \"corups.\",\n",
        "    # \"class.\",\n",
        "    # \"task, challenge\",\n",
        "# ]\n",
        "\n",
        "# queries = [\n",
        "#     \"Supporting Findings\",\n",
        "#     \"Validation of Hypotheses\",\n",
        "#     \"Empirical Analysis\",\n",
        "#     \"Comparative Studies\",\n",
        "#     \"Replication and Verification\",\n",
        "#     \"Methodological Transparency\",\n",
        "#     \"Citation and Attribution\",\n",
        "#     \"Benchmarking\",\n",
        "#     \"Standardization and Comparison\",\n",
        "#     \"Community Collaboration\"\n",
        "# ]\n",
        "\n",
        "\n",
        "query_embeds = prepare_embeddings(queries)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_range = [200,300]\n",
        "temp_range = [291,292]\n",
        "current_id = id_range[0] - 1\n",
        "\n",
        "# GLOBAL_DATASETS = {}\n",
        "datasets = set()\n",
        "\n",
        "for_range = temp_range\n",
        "\n",
        "for current_id in tqdm.tqdm(range(*for_range)):\n",
        "    chunks = py_.flow(\n",
        "        lambda x: get_text(dmdd, x),\n",
        "        sentence_splitter,\n",
        "        lambda x: group_sentences(x, 200, 2),\n",
        "    )(current_id)\n",
        "\n",
        "    dataset_keywords = []\n",
        "\n",
        "    while True:\n",
        "        keywords = regex_keywords_phrases if len(datasets) < 1 else dataset_keywords\n",
        "\n",
        "        corpus = prepare_corpus(chunks, keywords=keywords, regex=len(datasets) < 1)\n",
        "        corpus_embeds = prepare_embeddings(corpus)\n",
        "\n",
        "        queries_hits = util.semantic_search(query_embeds, corpus_embeds, top_k=20)\n",
        "        docs = resolve_hit_documents(corpus, queries_hits)\n",
        "\n",
        "        grounding_passages = prepare_grounding_passages(docs)\n",
        "\n",
        "        query_content = prepare_query_content(\n",
        "            \"Example datasets found are: {}.\".format(\", \".join(datasets)) if len(datasets) > 0 else \"\"\n",
        "        )\n",
        "\n",
        "\n",
        "        response = generate_answer(grounding_passages, query_content)\n",
        "        attempted_answer = py_.attempt(lambda _: response.answer.content.parts[0].text, None)\n",
        "        ic(attempted_answer)\n",
        "\n",
        "        if (py_.is_error(attempted_answer)):\n",
        "            print(attempted_answer)\n",
        "            break\n",
        "\n",
        "        for text_in_brackets in re.findall(r\"\\((.*?)\\)\", attempted_answer):\n",
        "            if not re.search(r\"\\( *(?:[\\w& \\.,*-]+\\d{4};?)+ *\\)\", text_in_brackets):\n",
        "                continue\n",
        "            attempted_answer = re.sub(rf\"\\({text_in_brackets}\\)\", \"\", attempted_answer)\n",
        "\n",
        "        temp_baselines = py_.chain(attempted_answer.split(\", \")).map_(lambda x: x.strip()).filter_(lambda x: len(x.split(\" \")) < 7).apply(list).value()\n",
        "        temp_baselines = datasets.union(temp_baselines)\n",
        "\n",
        "        if temp_baselines - datasets == set():\n",
        "            break\n",
        "\n",
        "        datasets = temp_baselines\n",
        "        dataset_keywords = datasets\n",
        "\n",
        "        for dataset in datasets:\n",
        "            if m := re.findall(r\"\\((.*?)\\)\", dataset):\n",
        "                m = [_.strip() for _ in m]\n",
        "                dataset_keywords = dataset_keywords.union(m)\n",
        "                dataset_keywords = dataset_keywords.union(\n",
        "                    {re.sub(rf\"\\({_}\\)\", \"\", dataset).strip() for _ in m}\n",
        "                )\n",
        "\n",
        "    GLOBAL_DATASETS[current_id] = py_.chain(datasets).map_(sub_ci(\" +\",\" \")).filter_(lambda x: len(x) > 0).apply(list).value()\n",
        "    datasets = set()"
      ],
      "metadata": {
        "id": "XPdFZ3GYRMh_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3125301a-a588-496f-cac8-d218a3d11731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]ic| attempted_answer: 'Continuous Hopfield Network'\n",
            "ic| attempted_answer: 'input data set, x (t)'\n",
            "ic| attempted_answer: 'x (t), Continuous Hopfield Network, input data set'\n",
            "100%|██████████| 1/1 [00:49<00:00, 49.34s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GLOBAL_DATASETS"
      ],
      "metadata": {
        "id": "XaIZXEANmkqT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2200d1f6-7e86-4cca-cc2a-a26d02a3fca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{200: ['MatchNMingle', 'SALSA'],\n",
              " 201: ['SUNCG', 'MVS', 'SUN3D'],\n",
              " 202: ['MARS', 'PRID 2011', 'iLIDS-VID'],\n",
              " 203: ['The People-Snapshot dataset', 'the dataset used in'],\n",
              " 204: ['train', 'test1&2', 'development'],\n",
              " 205: ['IBUG', 'COFW', 'AFLW'],\n",
              " 206: ['Multi-View Stereo Correspondence (MVS-Corr)', 'HPatches'],\n",
              " 207: ['ShapeNet', 'SHAPENET'],\n",
              " 208: ['HAM10000 Dataset'],\n",
              " 209: ['CIFAR-10', 'ImageNet-100'],\n",
              " 210: ['PASCAL VOC', 'MS-COCO'],\n",
              " 211: ['FlyingChairs', 'FlyingThings3D', 'ChairsSDHom'],\n",
              " 212: ['Amazon Reviews dataset',\n",
              "  'IMDB movie review datasets',\n",
              "  'Binary Stanford Sentiment Treebank (SST)'],\n",
              " 213: ['T matrix',\n",
              "  'SqueezeDet',\n",
              "  'T overlap',\n",
              "  'X overlap',\n",
              "  'Driving in the Matrix',\n",
              "  'X matrix'],\n",
              " 214: ['sketch perceptual grouping (SPG) dataset'],\n",
              " 215: ['ORL', 'YALE', 'MNIST'],\n",
              " 216: ['Im2GPS3k', 'Im2GPS test set', 'Im2GPS', 'YFCC4k'],\n",
              " 217: ['Caltech-USA dataset', 'Caltech10 training set', 'KITTI dataset'],\n",
              " 218: ['x-shaped Gaussian', 'banana distribution', 'multimodal Gaussian'],\n",
              " 219: ['global radiation extrapolation',\n",
              "  'sliding mean ozone concentration',\n",
              "  'Gaussian Table',\n",
              "  'temperature evolution'],\n",
              " 220: ['SUNCG dataset'],\n",
              " 221: ['2nd Social Media Mining for Health Applications Shared Task at AMIA 2017'],\n",
              " 222: ['Spoken-SQuAD', 'ODSQA'],\n",
              " 223: ['PF-WILLOW',\n",
              "  'Tokyo Time Machine',\n",
              "  'PASCAL Parts',\n",
              "  \"Taniai's dataset\",\n",
              "  'PF-PASCAL',\n",
              "  'PASCAL VOC 2011',\n",
              "  'Caltech 101'],\n",
              " 224: ['LVQuan18'],\n",
              " 225: ['DEAP', 'SEED'],\n",
              " 226: ['Huji EgoSet',\n",
              "  'UTEgocentric',\n",
              "  'R3',\n",
              "  'First Person Social Interaction Dataset',\n",
              "  'CLEF',\n",
              "  'NTCIR',\n",
              "  'EDUB-SegDesc',\n",
              "  'EDUB-Seg'],\n",
              " 227: ['Guangzhou'],\n",
              " 228: ['UCR archive', 'DiatomSizeReduction', 'UCR TSC benchmark', 'Wine'],\n",
              " 229: ['Genomic Data Commons (GDC) that includes The Cancer Genome Atlas (TCGA) and Therapeutically Applicable Research to Generate Effective Treatments (TARGET) programs'],\n",
              " 230: ['Coarse Discourse Dataset',\n",
              "  'Facebook discussion dataset',\n",
              "  'Reddit dataset'],\n",
              " 231: ['Stanford Bunny', 'Stanford Lounge'],\n",
              " 232: ['QMUL', 'Sketchy', 'QuickDraw', 'TU-Berlin'],\n",
              " 233: ['Motorbike Urban Dataset', 'Matlab example', 'Las Vegas'],\n",
              " 234: ['KITTI'],\n",
              " 235: ['GlobalPhone', 'TIMIT'],\n",
              " 236: ['three-ring dataset'],\n",
              " 237: ['Smokes-Cancer-Friends', 'WebKB', 'Movie Lens', 'UW-CSE', 'IMDB'],\n",
              " 238: ['TUT Acoustic Scenes 2017 dataset',\n",
              "  'TUT Acoustic Scenes 2017 Features 1',\n",
              "  'Google AudioSet'],\n",
              " 239: ['Microsoft Common Objects in Context (MS-COCO)',\n",
              "  'ImageNet',\n",
              "  'SpaceNet 1',\n",
              "  'PASCAL VOC 2012'],\n",
              " 240: ['LSUN dataset', 'Hedau dataset', 'SUN RGB-D dataset'],\n",
              " 241: ['MPII Human Pose',\n",
              "  'Leeds Sports Pose (LSP)',\n",
              "  'LFPW',\n",
              "  'IBUG',\n",
              "  'HELEN',\n",
              "  'AFW'],\n",
              " 242: ['Strecha SfM dataset', 'TUM SLAM dataset', 'KITTI odometry benchmark'],\n",
              " 243: ['Leeds sports pose (LSP)'],\n",
              " 244: ['UT-Zap50K', 'QMUL-Shoe-V2'],\n",
              " 245: ['MSR-VTT', 'LSMDC'],\n",
              " 246: ['English Gigaword Corpus',\n",
              "  'British national corpus',\n",
              "  \"Oxford Advanced Learner's Dictionary\"],\n",
              " 247: ['Real-World Affective Faces',\n",
              "  'AVEC',\n",
              "  'AFEW',\n",
              "  'EmotioNet',\n",
              "  'AffectNet',\n",
              "  'FERA'],\n",
              " 248: ['MIMIC-III'],\n",
              " 249: [\"Alzheimer's Disease Neuroimaging Initiative (ADNI) database\"],\n",
              " 251: ['CIFAR-10', 'ImageNet', 'MNIST'],\n",
              " 252: ['The Arabic to English dataset extracted from Wikipedia titles in',\n",
              "  'The CMU pronunciation dictionary'],\n",
              " 253: ['GRIMA database of X-ray images (GDXray) dataset'],\n",
              " 254: ['Penndataset', 'HUJI-dataset'],\n",
              " 255: ['Caltech-UCSD Birds 200 (CUB)', 'Animals with Attributes 2 (AWA2)'],\n",
              " 256: ['VQA dataset', 'CLEVR dataset'],\n",
              " 257: ['ImageNet', 'CIFAR-100'],\n",
              " 258: ['LIVE-QA 2015 dataset', 'TREC-QA answer sentence selection dataset'],\n",
              " 259: ['ActivityNet'],\n",
              " 260: ['MT-ComparEval', 'iBLEU'],\n",
              " 261: ['REDDIT-BINARY',\n",
              "  'REDDIT-MULTI-5K',\n",
              "  'IMDB-BINARY',\n",
              "  'NCI1',\n",
              "  'IMDB-MULTI',\n",
              "  'QM9',\n",
              "  'MUTAG',\n",
              "  'PROTEINS',\n",
              "  'COL-LAB',\n",
              "  'ENZYMES',\n",
              "  'Synthie'],\n",
              " 262: ['Ima-geNet'],\n",
              " 263: ['IMDB movie data set'],\n",
              " 264: ['SURREAL', 'MPII', 'ScanAva', 'MPII dataset'],\n",
              " 265: ['Y'],\n",
              " 266: ['MRC datasets'],\n",
              " 267: ['AIS'],\n",
              " 268: ['Emergent', 'FNC-1'],\n",
              " 269: ['Fashion', 'MNIST'],\n",
              " 270: ['HCI benchmark',\n",
              "  'Stanford Light Field Archive',\n",
              "  'Lytro Illum light field camera',\n",
              "  'New light fields rendered with Blender',\n",
              "  '4D light field benchmark',\n",
              "  'Real-world light fields'],\n",
              " 271: ['ImageNet'],\n",
              " 272: ['video compression dataset', 'Youtube', 'DAVIS'],\n",
              " 273: ['MNIST'],\n",
              " 274: ['ShapeNet', 'SUN database'],\n",
              " 275: ['Extended Cohn-Kanade (CK+)', 'CK++'],\n",
              " 276: ['AI2'],\n",
              " 277: ['illustration dataset', 'line art dataset'],\n",
              " 278: ['Microsoft COCO'],\n",
              " 279: ['ModelNet'],\n",
              " 280: ['HAM10000 Dataset', 'ISIC Skin Image Analysis Challenge'],\n",
              " 281: ['covering 153 different products', '7,119 questions'],\n",
              " 282: ['co-purchase dataset from Amazon e-commerce domain',\n",
              "  'Amazon e-commerce domain',\n",
              "  'job training dataset'],\n",
              " 283: ['Twocircles-MVO',\n",
              "  'Gowalla Check-In dataset',\n",
              "  'MLS SOCCER dataset',\n",
              "  'Jain-MVO',\n",
              "  'Aggregation-MVO',\n",
              "  'Compound-MVO'],\n",
              " 284: ['CIFAR-10', 'CIFAR-100'],\n",
              " 285: ['SBD', 'Cityscapes', 'Microsoft COCO', 'Pascal VOC'],\n",
              " 286: ['SRCNN'],\n",
              " 287: ['empirical risk minimization'],\n",
              " 288: ['Taobao'],\n",
              " 289: ['SUNCG', 'NYU Depth v2'],\n",
              " 290: ['Apple ARKit'],\n",
              " 291: ['x (t)', 'Continuous Hopfield Network', 'input data set'],\n",
              " 292: ['FIRE 2013', 'FIRE 2014'],\n",
              " 293: ['MNIST'],\n",
              " 294: ['MS-COCO'],\n",
              " 295: ['Emergent', 'FEVER'],\n",
              " 296: ['Resource Management (RM)', 'Wall Street Journal (WSJ)'],\n",
              " 297: ['Fashion MNIST', 'MNIST'],\n",
              " 298: ['VOT', 'ViZDoom', 'UE'],\n",
              " 299: ['English', 'CoNLL-2008', 'Chinese', 'CoNLL-2009']}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# id_range = [0,100]\n",
        "\n",
        "with open(\n",
        "    f\"./drive/MyDrive/Thesis/Dataset_Extraction/raw dataset/dmdd_modified/{id_range[0]}_{id_range[1] - 1}.pkl\",\n",
        "    \"wb\",\n",
        ") as file:\n",
        "    pickle.dump(file=file, obj=GLOBAL_DATASETS, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "# with open(\n",
        "#     f\"./drive/MyDrive/Thesis/Dataset_Extraction/raw dataset/dmdd_modified/{id_range[0]}_{id_range[1] - 1}.pkl\",\n",
        "#     \"rb\",\n",
        "# ) as file:\n",
        "#     GLOBAL_DATASETS = pickle.load(file=file)"
      ],
      "metadata": {
        "id": "6rqQ0m3bSSeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title function to generate scores\n",
        "def score_fn(observed, ground) -> dict[str,None|set]:\n",
        "\n",
        "    stop_words = [\"the\"]\n",
        "\n",
        "    def f(text):\n",
        "        text = sub_ci(\"(data ?set|database|corpus|caption|benchmark|train|test).*\",\"\")(text)\n",
        "        text = py_.flow(*py_.chain(stop_words).map_(lambda x: sub_ci(x, \"\")).value())(text)\n",
        "        return re.sub(r\" +\",\" \",text).strip()\n",
        "\n",
        "    original = {\n",
        "        \"ground\": {f(text).lower(): text for text in ground},\n",
        "    }\n",
        "\n",
        "    temp = {}\n",
        "    for o in observed:\n",
        "        m = re.findall(r\"\\((.*)\\)\",o.lower())\n",
        "        if len(m) > 0:\n",
        "            temp[f(m[0])] = o\n",
        "            d_ = f(o.lower().replace(f\"({m[0]})\",\"\").strip())\n",
        "            if len(d_) > 0:\n",
        "                temp[d_] = o\n",
        "                if len(d_.split(\" \")) > 1:\n",
        "                    temp[py_.chain(d_.split(\" \")).map_(lambda x: x[0].upper()).apply(py_.strings.join).value()] = o\n",
        "        else:\n",
        "            if len(d_ := f(o.lower())) > 1:\n",
        "                temp[d_] = o\n",
        "                if len(d_.split(\" \")) > 1:\n",
        "                    temp[py_.chain(d_.split(\" \")).map_(lambda x: x[0]).apply(py_.strings.join).value()] = o\n",
        "\n",
        "    original['observed'] = temp\n",
        "\n",
        "    ground = set(map(f, original['ground'].keys()))\n",
        "    observed = set(original['observed'].keys())\n",
        "\n",
        "\n",
        "    # TP: True Positives (correctly predicted positive instances)\n",
        "    # TN: True Negatives (correctly predicted negative instances)\n",
        "    # FP: False Positives (incorrectly predicted as positive instances)\n",
        "    # FN: False Negatives (incorrectly predicted as negative instances)\n",
        "\n",
        "\n",
        "    fp = set()\n",
        "    tp = set()\n",
        "    temp = set()\n",
        "    for g in ground:\n",
        "        for o in observed:\n",
        "            if  o == g :\n",
        "                # ic(o,g)\n",
        "                tp.add(original['ground'][g])\n",
        "                temp.add(g)\n",
        "                break\n",
        "\n",
        "    for o in observed:\n",
        "        for g in ground:\n",
        "            if o == g:\n",
        "                # ic(o,g)\n",
        "                break\n",
        "        else:\n",
        "            # ic(o)\n",
        "            if original['observed'][o] not in tp:\n",
        "                fp.add(original['observed'][o])\n",
        "\n",
        "    # ic(tp, fp)\n",
        "\n",
        "    new = fp\n",
        "    observed = observed.union(temp)\n",
        "\n",
        "    tp = len(tp)\n",
        "    # tp = len(ground.intersection(observed))\n",
        "    fp = len(fp)\n",
        "    # fp = len(observed - ground)\n",
        "    tn = 0\n",
        "    fn = len(ground - observed)\n",
        "\n",
        "\n",
        "    if tp+fp == 0:\n",
        "        precision = None\n",
        "    else:\n",
        "        precision = tp / (tp + fp)\n",
        "\n",
        "    if tp+fn == 0:\n",
        "        recall = None\n",
        "    else:\n",
        "        recall = tp / (tp + fn)\n",
        "\n",
        "    if tp+tn+fp+fn == 0:\n",
        "        accuracy = None\n",
        "    else:\n",
        "        accuracy = (tp+tn) / (tp + tn + fp + fn)\n",
        "\n",
        "    ground_ds = list(map(lambda x: re.sub(\" +\", \" \", x), original['ground'].values()))\n",
        "    missed_ds = list(map(lambda x: re.sub(\" +\", \" \", x), {original['ground'][text] for text in ground - observed}))\n",
        "    new_ds = list(map(lambda x: re.sub(\" +\", \" \", x), new))\n",
        "\n",
        "    metric_scores = {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"accuracy\": accuracy,\n",
        "\n",
        "        \"ground\": ground_ds if len(ground_ds) > 0 else None,\n",
        "        \"missed\": missed_ds if len(missed_ds) > 0 else None,\n",
        "        \"new\": new_ds if len(new_ds) > 0 else None,\n",
        "    }\n",
        "    return metric_scores"
      ],
      "metadata": {
        "id": "wKZ7MbxzQ7bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "statistics = {}\n",
        "for id, datasets in tqdm.tqdm(GLOBAL_DATASETS.items()):\n",
        "    # if id == 190:\n",
        "    statistics[id] = score_fn(datasets, get_true_datasets(dmdd, id))\n",
        "\n",
        "df = pd.DataFrame(statistics).T\n",
        "# df.index.names = [\"DMDD ID\"]"
      ],
      "metadata": {
        "id": "4hEJidIQ-OV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a910ce-9b8c-4c73-fa42-6f41a08a40ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1768.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "xoS6mDvC0OHt",
        "outputId": "c2ebf927-a2a9-4132-afa8-72fac06df1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    precision recall accuracy                     ground              missed  \\\n",
              "200       0.5    1.0      0.5                    [SALSA]                None   \n",
              "201       0.0    0.0      0.0         [KITTI, TUM RGB-D]  [TUM RGB-D, KITTI]   \n",
              "202       0.0    0.0      0.0                 [ImageNet]          [ImageNet]   \n",
              "203       1.0    1.0      1.0  [People-snapshot dataset]                None   \n",
              "204       0.0   None      0.0                       None                None   \n",
              "..        ...    ...      ...                        ...                 ...   \n",
              "295       0.5    1.0      0.5                    [FEVER]                None   \n",
              "296       0.0   None      0.0                       None                None   \n",
              "297       0.5    1.0      0.5            [Fashion MNIST]                None   \n",
              "298  0.333333    0.5     0.25        [ViZDoom, ViZ-Doom]          [ViZ-Doom]   \n",
              "299       0.0   None      0.0                       None                None   \n",
              "\n",
              "                                                   new  \n",
              "200                                     [MatchNMingle]  \n",
              "201                                [SUNCG, MVS, SUN3D]  \n",
              "202                       [MARS, PRID 2011, iLIDS-VID]  \n",
              "203                                               None  \n",
              "204                                      [development]  \n",
              "..                                                 ...  \n",
              "295                                         [Emergent]  \n",
              "296  [Resource Management (RM), Wall Street Journal...  \n",
              "297                                            [MNIST]  \n",
              "298                                          [VOT, UE]  \n",
              "299         [English, Chinese, CoNLL-2008, CoNLL-2009]  \n",
              "\n",
              "[99 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d5bf236-c3a0-4f10-9da4-f59e0b94cf72\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>ground</th>\n",
              "      <th>missed</th>\n",
              "      <th>new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>[SALSA]</td>\n",
              "      <td>None</td>\n",
              "      <td>[MatchNMingle]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[KITTI, TUM RGB-D]</td>\n",
              "      <td>[TUM RGB-D, KITTI]</td>\n",
              "      <td>[SUNCG, MVS, SUN3D]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[ImageNet]</td>\n",
              "      <td>[ImageNet]</td>\n",
              "      <td>[MARS, PRID 2011, iLIDS-VID]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[People-snapshot dataset]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[development]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>[FEVER]</td>\n",
              "      <td>None</td>\n",
              "      <td>[Emergent]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[Resource Management (RM), Wall Street Journal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>[Fashion MNIST]</td>\n",
              "      <td>None</td>\n",
              "      <td>[MNIST]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>[ViZDoom, ViZ-Doom]</td>\n",
              "      <td>[ViZ-Doom]</td>\n",
              "      <td>[VOT, UE]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[English, Chinese, CoNLL-2008, CoNLL-2009]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d5bf236-c3a0-4f10-9da4-f59e0b94cf72')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0d5bf236-c3a0-4f10-9da4-f59e0b94cf72 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0d5bf236-c3a0-4f10-9da4-f59e0b94cf72');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c81840da-a429-47d7-9d1f-65c3df2bcf44\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c81840da-a429-47d7-9d1f-65c3df2bcf44')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c81840da-a429-47d7-9d1f-65c3df2bcf44 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "0"
            },
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/881c4a0d49046431/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 200,\n            'f': \"200\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n[\"SALSA\"],\nnull,\n[\"MatchNMingle\"]],\n [{\n            'v': 201,\n            'f': \"201\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"KITTI\", \"TUM RGB-D\"],\n[\"TUM RGB-D\", \"KITTI\"],\n[\"SUNCG\", \"MVS\", \"SUN3D\"]],\n [{\n            'v': 202,\n            'f': \"202\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"ImageNet\"],\n[\"ImageNet\"],\n[\"MARS\", \"PRID 2011\", \"iLIDS-VID\"]],\n [{\n            'v': 203,\n            'f': \"203\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n[\"People-snapshot dataset\"],\nnull,\nnull],\n [{\n            'v': 204,\n            'f': \"204\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"development\"]],\n [{\n            'v': 205,\n            'f': \"205\",\n        },\n{\n            'v': 0.6666666666666666,\n            'f': \"0.6666666666666666\",\n        },\n{\n            'v': 0.6666666666666666,\n            'f': \"0.6666666666666666\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n[\"AFLW\", \"LFPW\", \"COFW\"],\n[\"LFPW\"],\n[\"IBUG\"]],\n [{\n            'v': 206,\n            'f': \"206\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n[\"HPatches\"],\nnull,\n[\"Multi-View Stereo Correspondence (MVS-Corr)\"]],\n [{\n            'v': 207,\n            'f': \"207\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n[\"SHAPENET\"],\nnull,\nnull],\n [{\n            'v': 208,\n            'f': \"208\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n[\"HAM10000\"],\nnull,\nnull],\n [{\n            'v': 209,\n            'f': \"209\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n[\"ImageNet\", \"ImageNet-100\"],\n[\"ImageNet\"],\n[\"CIFAR-10\"]],\n [{\n            'v': 210,\n            'f': \"210\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"COCO\", \"ScribbleSup\"],\n[\"ScribbleSup\", \"COCO\"],\n[\"PASCAL VOC\", \"MS-COCO\"]],\n [{\n            'v': 211,\n            'f': \"211\",\n        },\n{\n            'v': 0.6666666666666666,\n            'f': \"0.6666666666666666\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.6666666666666666,\n            'f': \"0.6666666666666666\",\n        },\n[\"FlyingThings3D\", \"FlyingChairs\"],\nnull,\n[\"ChairsSDHom\"]],\n [{\n            'v': 212,\n            'f': \"212\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"ImageNet\"],\n[\"ImageNet\"],\n[\"Amazon Reviews dataset\", \"IMDB movie review datasets\", \"Binary Stanford Sentiment Treebank (SST)\"]],\n [{\n            'v': 213,\n            'f': \"213\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"CARLA\"],\n[\"CARLA\"],\n[\"T matrix\", \"X matrix\", \"T overlap\", \"X overlap\", \"Driving in the Matrix\", \"SqueezeDet\"]],\n [{\n            'v': 214,\n            'f': \"214\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"Sketch\"],\n[\"Sketch\"],\n[\"sketch perceptual grouping (SPG) dataset\"]],\n [{\n            'v': 215,\n            'f': \"215\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n[\"MNIST\"],\nnull,\n[\"ORL\", \"YALE\"]],\n [{\n            'v': 216,\n            'f': \"216\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"ImageNet\"],\n[\"ImageNet\"],\n[\"Im2GPS3k\", \"Im2GPS\", \"YFCC4k\"]],\n [{\n            'v': 217,\n            'f': \"217\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n[\"KITTI\"],\nnull,\n[\"Caltech-USA dataset\", \"Caltech10 training set\"]],\n [{\n            'v': 218,\n            'f': \"218\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"banana distribution\", \"x-shaped Gaussian\", \"multimodal Gaussian\"]],\n [{\n            'v': 219,\n            'f': \"219\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"global radiation extrapolation\", \"sliding mean ozone concentration\", \"Gaussian Table\", \"temperature evolution\"]],\n [{\n            'v': 220,\n            'f': \"220\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n[\"ShapeNet\", \"SUNCG\"],\n[\"ShapeNet\"],\nnull],\n [{\n            'v': 221,\n            'f': \"221\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"2nd Social Media Mining for Health Applications Shared Task at AMIA 2017\"]],\n [{\n            'v': 222,\n            'f': \"222\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.2,\n            'f': \"0.2\",\n        },\n{\n            'v': 0.2,\n            'f': \"0.2\",\n        },\n[\"ODSQA\", \"Open-Domain Spoken Question Answering\", \"SQuAD\", \"Spoken-SQuAD\", \"Stanford Question Answering Dataset\", \"MovieQA\", \"DRCD\", \"DRCD-TTS\", \"DRCD-backtrans\", \"Delta Reading Comprehension Dataset\"],\n[\"DRCD-backtrans\", \"SQuAD\", \"DRCD\", \"Stanford Question Answering Dataset\", \"Open-Domain Spoken Question Answering\", \"MovieQA\", \"Delta Reading Comprehension Dataset\", \"DRCD-TTS\"],\nnull],\n [{\n            'v': 223,\n            'f': \"223\",\n        },\n{\n            'v': 0.14285714285714285,\n            'f': \"0.14285714285714285\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.14285714285714285,\n            'f': \"0.14285714285714285\",\n        },\n[\"PASCAL VOC 2011\"],\nnull,\n[\"PF-WILLOW\", \"Taniai's dataset\", \"PF-PASCAL\", \"Tokyo Time Machine\", \"PASCAL Parts\", \"Caltech 101\"]],\n [{\n            'v': 224,\n            'f': \"224\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"LVQuan18\"]],\n [{\n            'v': 225,\n            'f': \"225\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n[\"SEED:\", \"SEED\"],\n[\"SEED:\"],\n[\"DEAP\"]],\n [{\n            'v': 226,\n            'f': \"226\",\n        },\n{\n            'v': 0.125,\n            'f': \"0.125\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.125,\n            'f': \"0.125\",\n        },\n[\"EDUB-Seg\"],\nnull,\n[\"Huji EgoSet\", \"UTEgocentric\", \"R3\", \"First Person Social Interaction Dataset\", \"CLEF\", \"NTCIR\", \"EDUB-SegDesc\"]],\n [{\n            'v': 227,\n            'f': \"227\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"Guangzhou\"]],\n [{\n            'v': 228,\n            'f': \"228\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"Wine\", \"UCR archive\", \"DiatomSizeReduction\", \"UCR TSC benchmark\"]],\n [{\n            'v': 229,\n            'f': \"229\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"Genomic Data Commons (GDC) that includes The Cancer Genome Atlas (TCGA) and Therapeutically Applicable Research to Generate Effective Treatments (TARGET) programs\"]],\n [{\n            'v': 230,\n            'f': \"230\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"Coarse Discourse Dataset\", \"Facebook discussion dataset\", \"Reddit dataset\"]],\n [{\n            'v': 231,\n            'f': \"231\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"KITTI\"],\n[\"KITTI\"],\n[\"Stanford Bunny\", \"Stanford Lounge\"]],\n [{\n            'v': 232,\n            'f': \"232\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"SketchyScene\", \"SketchyScene/\", \"sketchy scene\", \"ImageNet\", \"COCO\", \"Sketch\"],\n[\"ImageNet\", \"sketchy scene\", \"SketchyScene/\", \"SketchyScene\", \"Sketch\", \"COCO\"],\n[\"QMUL\", \"Sketchy\", \"QuickDraw\", \"TU-Berlin\"]],\n [{\n            'v': 233,\n            'f': \"233\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"KITTI\"],\n[\"KITTI\"],\n[\"Motorbike Urban Dataset\", \"Matlab example\", \"Las Vegas\"]],\n [{\n            'v': 234,\n            'f': \"234\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"KITTI\"]],\n [{\n            'v': 235,\n            'f': \"235\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"GlobalPhone\", \"TIMIT\"]],\n [{\n            'v': 236,\n            'f': \"236\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"ImageNet\"],\n[\"ImageNet\"],\n[\"three-ring dataset\"]],\n [{\n            'v': 237,\n            'f': \"237\",\n        },\n{\n            'v': 0.2,\n            'f': \"0.2\",\n        },\n{\n            'v': 0.25,\n            'f': \"0.25\",\n        },\n{\n            'v': 0.125,\n            'f': \"0.125\",\n        },\n[\"Movie Lens:\", \"MovieLens\", \"WebKB:\", \"WebKB\"],\n[\"MovieLens\", \"Movie Lens:\", \"WebKB:\"],\n[\"Smokes-Cancer-Friends\", \"Movie Lens\", \"IMDB\", \"UW-CSE\"]],\n [{\n            'v': 238,\n            'f': \"238\",\n        },\n{\n            'v': 0.25,\n            'f': \"0.25\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.25,\n            'f': \"0.25\",\n        },\n[\"TUT Acoustic Scenes 2017\"],\nnull,\n[\"TUT Acoustic Scenes 2017 dataset\", \"TUT Acoustic Scenes 2017 Features 1\", \"Google AudioSet\"]],\n [{\n            'v': 239,\n            'f': \"239\",\n        },\n{\n            'v': 0.2,\n            'f': \"0.2\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.16666666666666666,\n            'f': \"0.16666666666666666\",\n        },\n[\"COCO\", \"Microsoft Common Objects in Context\"],\n[\"COCO\"],\n[\"Microsoft Common Objects in Context (MS-COCO)\", \"SpaceNet 1\", \"ImageNet\", \"PASCAL VOC 2012\"]],\n [{\n            'v': 240,\n            'f': \"240\",\n        },\n{\n            'v': 0.25,\n            'f': \"0.25\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.2,\n            'f': \"0.2\",\n        },\n[\"SUN RGB-D\", \"Watch-n-Patch\"],\n[\"Watch-n-Patch\"],\n[\"LSUN dataset\", \"Hedau dataset\", \"SUN RGB-D dataset\"]],\n [{\n            'v': 241,\n            'f': \"241\",\n        },\n{\n            'v': 0.375,\n            'f': \"0.375\",\n        },\n{\n            'v': 0.75,\n            'f': \"0.75\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n[\"MPII Human Pose\", \"MPII\", \"LSP\", \"Leeds Sports Pose\"],\n[\"MPII\"],\n[\"Leeds Sports Pose (LSP)\", \"LFPW\", \"IBUG\", \"HELEN\", \"AFW\"]],\n [{\n            'v': 242,\n            'f': \"242\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"KITTI\"],\n[\"KITTI\"],\n[\"Strecha SfM dataset\", \"TUM SLAM dataset\", \"KITTI odometry benchmark\"]],\n [{\n            'v': 243,\n            'f': \"243\",\n        },\n{\n            'v': 0.6666666666666666,\n            'f': \"0.6666666666666666\",\n        },\n{\n            'v': 0.25,\n            'f': \"0.25\",\n        },\n{\n            'v': 0.2222222222222222,\n            'f': \"0.2222222222222222\",\n        },\n[\"MPII\", \"MPII Human Pose\", \"MPII-GPM\", \"LSP\", \"Leeds sports pose\", \"SURREAL\", \"SURREAL-GPM\", \"Synthetic hUmans foR REAL tasks\"],\n[\"SURREAL-GPM\", \"MPII Human Pose\", \"MPII\", \"MPII-GPM\", \"SURREAL\", \"Synthetic hUmans foR REAL tasks\"],\n[\"Leeds sports pose (LSP)\"]],\n [{\n            'v': 244,\n            'f': \"244\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"Sketch\"],\n[\"Sketch\"],\n[\"UT-Zap50K\", \"QMUL-Shoe-V2\"]],\n [{\n            'v': 245,\n            'f': \"245\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.6666666666666666,\n            'f': \"0.6666666666666666\",\n        },\n{\n            'v': 0.6666666666666666,\n            'f': \"0.6666666666666666\",\n        },\n[\"MSR-VTT\", \"LSMDC\", \"LSMDC:\"],\n[\"LSMDC:\"],\nnull],\n [{\n            'v': 246,\n            'f': \"246\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"English Gigaword Corpus\", \"British national corpus\", \"Oxford Advanced Learner's Dictionary\"]],\n [{\n            'v': 247,\n            'f': \"247\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.25,\n            'f': \"0.25\",\n        },\n[\"IEMOCAP\", \"AffectNet\", \"Real-World Affective Faces\", \"SFEW\"],\n[\"SFEW\", \"IEMOCAP\"],\n[\"EmotioNet\", \"FERA\", \"AVEC\", \"AFEW\"]],\n [{\n            'v': 248,\n            'f': \"248\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n[\"MIMIC-III\"],\nnull,\nnull],\n [{\n            'v': 249,\n            'f': \"249\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"Alzheimer's Disease Neuroimaging Initiative (ADNI) database\"]],\n [{\n            'v': 251,\n            'f': \"251\",\n        },\n{\n            'v': 0.6666666666666666,\n            'f': \"0.6666666666666666\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.6666666666666666,\n            'f': \"0.6666666666666666\",\n        },\n[\"CIFAR-10\", \"MNIST\"],\nnull,\n[\"ImageNet\"]],\n [{\n            'v': 252,\n            'f': \"252\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"The Arabic to English dataset extracted from Wikipedia titles in\", \"The CMU pronunciation dictionary\"]],\n [{\n            'v': 253,\n            'f': \"253\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"COCO\", \"Microsoft Common Objects in Context\"],\n[\"Microsoft Common Objects in Context\", \"COCO\"],\n[\"GRIMA database of X-ray images (GDXray) dataset\"]],\n [{\n            'v': 254,\n            'f': \"254\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"CelebA\", \"ExpW\"],\n[\"ExpW\", \"CelebA\"],\n[\"Penndataset\", \"HUJI-dataset\"]],\n [{\n            'v': 255,\n            'f': \"255\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.25,\n            'f': \"0.25\",\n        },\n[\"ImageNet\", \"CUB\"],\n[\"ImageNet\"],\n[\"Caltech-UCSD Birds 200 (CUB)\", \"Animals with Attributes 2 (AWA2)\"]],\n [{\n            'v': 256,\n            'f': \"256\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n[\"COCO\", \"visual question answering\", \"VQA\", \"CLEVR\"],\n[\"visual question answering\", \"COCO\"],\nnull],\n [{\n            'v': 257,\n            'f': \"257\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n[\"CIFAR-100\"],\nnull,\n[\"ImageNet\"]],\n [{\n            'v': 258,\n            'f': \"258\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"TREC-QA\"],\n[\"TREC-QA\"],\n[\"LIVE-QA 2015 dataset\", \"TREC-QA answer sentence selection dataset\"]],\n [{\n            'v': 259,\n            'f': \"259\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n[\"ActivityNet\"],\nnull,\nnull],\n [{\n            'v': 260,\n            'f': \"260\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"MT-ComparEval\", \"iBLEU\"]],\n [{\n            'v': 261,\n            'f': \"261\",\n        },\n{\n            'v': 0.36363636363636365,\n            'f': \"0.36363636363636365\",\n        },\n{\n            'v': 0.8,\n            'f': \"0.8\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n[\"PROTEINS\", \"COLLAB\", \"ENZYMES\", \"REDDIT-BINARY\", \"REDDIT-MULTI-5K\"],\n[\"COLLAB\"],\n[\"IMDB-BINARY\", \"NCI1\", \"IMDB-MULTI\", \"QM9\", \"MUTAG\", \"COL-LAB\", \"Synthie\"]],\n [{\n            'v': 262,\n            'f': \"262\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"CIFAR-100\"],\n[\"CIFAR-100\"],\n[\"Ima-geNet\"]],\n [{\n            'v': 263,\n            'f': \"263\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"CIFAR10\", \"CIFAR10:\", \"MNIST\", \"MNIST:\", \"AG news\"],\n[\"MNIST:\", \"MNIST\", \"AG news\", \"CIFAR10\", \"CIFAR10:\"],\n[\"IMDB movie data set\"]],\n [{\n            'v': 264,\n            'f': \"264\",\n        },\n{\n            'v': 0.6666666666666666,\n            'f': \"0.6666666666666666\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.4,\n            'f': \"0.4\",\n        },\n[\"LSUN\", \"MPII\", \"MPII human pose\", \"SURREAL\"],\n[\"MPII human pose\", \"LSUN\"],\n[\"ScanAva\"]],\n [{\n            'v': 265,\n            'f': \"265\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\nnull,\nnull,\nnull],\n [{\n            'v': 266,\n            'f': \"266\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"CBT\", \"CBT-NE\", \"Children's Book Test\", \"CMRC-2017\"],\n[\"CBT-NE\", \"Children's Book Test\", \"CBT\", \"CMRC-2017\"],\n[\"MRC datasets\"]],\n [{\n            'v': 267,\n            'f': \"267\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"AIS\"]],\n [{\n            'v': 268,\n            'f': \"268\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"Emergent\", \"FNC-1\"]],\n [{\n            'v': 269,\n            'f': \"269\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n[\"MNIST\", \"MNIST;\"],\n[\"MNIST;\"],\n[\"Fashion\"]],\n [{\n            'v': 270,\n            'f': \"270\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"Stanford Light Field Archive\", \"Lytro Illum light field camera\", \"New light fields rendered with Blender\", \"4D light field benchmark\", \"Real-world light fields\", \"HCI benchmark\"]],\n [{\n            'v': 271,\n            'f': \"271\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n[\"ImageNet\"],\nnull,\nnull],\n [{\n            'v': 272,\n            'f': \"272\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n[\"DAVIS\"],\nnull,\n[\"video compression dataset\", \"Youtube\"]],\n [{\n            'v': 273,\n            'f': \"273\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"MNIST\"]],\n [{\n            'v': 274,\n            'f': \"274\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n[\"ShapeNet\"],\nnull,\n[\"SUN database\"]],\n [{\n            'v': 275,\n            'f': \"275\",\n        },\n{\n            'v': 0.6666666666666666,\n            'f': \"0.6666666666666666\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.6666666666666666,\n            'f': \"0.6666666666666666\",\n        },\n[\"CK+\", \"CK++\"],\nnull,\n[\"Extended Cohn-Kanade (CK+)\"]],\n [{\n            'v': 276,\n            'f': \"276\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"framenet\"],\n[\"framenet\"],\n[\"AI2\"]],\n [{\n            'v': 277,\n            'f': \"277\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"illustration dataset\", \"line art dataset\"]],\n [{\n            'v': 278,\n            'f': \"278\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"COCO\"],\n[\"COCO\"],\n[\"Microsoft COCO\"]],\n [{\n            'v': 279,\n            'f': \"279\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n[\"ModelNet\"],\nnull,\nnull],\n [{\n            'v': 280,\n            'f': \"280\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n[\"HAM10000\"],\nnull,\n[\"ISIC Skin Image Analysis Challenge\"]],\n [{\n            'v': 281,\n            'f': \"281\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"WikiQA\"],\n[\"WikiQA\"],\n[\"7,119 questions\", \"covering 153 different products\"]],\n [{\n            'v': 282,\n            'f': \"282\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"co-purchase dataset from Amazon e-commerce domain\", \"Amazon e-commerce domain\", \"job training dataset\"]],\n [{\n            'v': 283,\n            'f': \"283\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"Gowalla\"],\n[\"Gowalla\"],\n[\"Twocircles-MVO\", \"Gowalla Check-In dataset\", \"MLS SOCCER dataset\", \"Jain-MVO\", \"Aggregation-MVO\", \"Compound-MVO\"]],\n [{\n            'v': 284,\n            'f': \"284\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"CIFAR-10\", \"CIFAR-100\"]],\n [{\n            'v': 285,\n            'f': \"285\",\n        },\n{\n            'v': 0.25,\n            'f': \"0.25\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.2,\n            'f': \"0.2\",\n        },\n[\"COCO\", \"Cityscapes\"],\n[\"COCO\"],\n[\"SBD\", \"Microsoft COCO\", \"Pascal VOC\"]],\n [{\n            'v': 286,\n            'f': \"286\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"ImageNet\", \"DIV2K\"],\n[\"DIV2K\", \"ImageNet\"],\n[\"SRCNN\"]],\n [{\n            'v': 287,\n            'f': \"287\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"empirical risk minimization\"]],\n [{\n            'v': 288,\n            'f': \"288\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"e-commerce\"],\n[\"e-commerce\"],\n[\"Taobao\"]],\n [{\n            'v': 289,\n            'f': \"289\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n[\"SUNCG\"],\nnull,\n[\"NYU Depth v2\"]],\n [{\n            'v': 290,\n            'f': \"290\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"Apple ARKit\"]],\n [{\n            'v': 291,\n            'f': \"291\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"x (t)\", \"Continuous Hopfield Network\", \"input data set\"]],\n [{\n            'v': 292,\n            'f': \"292\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"FIRE 2013\", \"FIRE 2014\"]],\n [{\n            'v': 293,\n            'f': \"293\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n[\"MNIST\", \"SVHN\"],\n[\"SVHN\"],\nnull],\n [{\n            'v': 294,\n            'f': \"294\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n[\"COCO\"],\n[\"COCO\"],\n[\"MS-COCO\"]],\n [{\n            'v': 295,\n            'f': \"295\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n[\"FEVER\"],\nnull,\n[\"Emergent\"]],\n [{\n            'v': 296,\n            'f': \"296\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"Resource Management (RM)\", \"Wall Street Journal (WSJ)\"]],\n [{\n            'v': 297,\n            'f': \"297\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n[\"Fashion MNIST\"],\nnull,\n[\"MNIST\"]],\n [{\n            'v': 298,\n            'f': \"298\",\n        },\n{\n            'v': 0.3333333333333333,\n            'f': \"0.3333333333333333\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        },\n{\n            'v': 0.25,\n            'f': \"0.25\",\n        },\n[\"ViZDoom\", \"ViZ-Doom\"],\n[\"ViZ-Doom\"],\n[\"VOT\", \"UE\"]],\n [{\n            'v': 299,\n            'f': \"299\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\nnull,\nnull,\n[\"English\", \"Chinese\", \"CoNLL-2008\", \"CoNLL-2009\"]]],\n        columns: [[\"number\", \"index\"], [\"number\", \"precision\"], [\"number\", \"recall\"], [\"number\", \"accuracy\"], [\"string\", \"ground\"], [\"string\", \"missed\"], [\"string\", \"new\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n<div id=\"df-66ffd50d-0f9b-484b-8c6d-cc6f37a59d7c\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66ffd50d-0f9b-484b-8c6d-cc6f37a59d7c')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n    \n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n  \n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-66ffd50d-0f9b-484b-8c6d-cc6f37a59d7c button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    "
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel(f\"./drive/MyDrive/Thesis/Dataset_Extraction/statistics/dmdd_modified/{id_range[0]}_{id_range[1] - 1}.xlsx\")"
      ],
      "metadata": {
        "id": "moDf5GMnTofl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_detected = []\n",
        "\n",
        "# for dmdd_id in [54]:\n",
        "for dmdd_id in tqdm.tqdm(df.T):\n",
        "    sentences = sentence_splitter(get_text(dmdd, dmdd_id))\n",
        "    chunks = group_sentences(sentences, 20, 0)\n",
        "    if df.T[dmdd_id][\"new\"] == None:\n",
        "        continue\n",
        "    for dataset in df.T[dmdd_id][\"new\"]:\n",
        "        context_arr = set()\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            context = []\n",
        "            k = 0\n",
        "            while True:\n",
        "                if dataset not in chunk:\n",
        "                    break\n",
        "                context = chunks[\n",
        "                    0 if i < (2 - k) else i - (2 - k) : (\n",
        "                        len(chunks)\n",
        "                        if i > len(chunks) - (3 - k)\n",
        "                        else i + (3 - k)\n",
        "                    )\n",
        "                ]\n",
        "                if len(\" \".join(context)) <= 700 or k > 1:\n",
        "                    break\n",
        "                k += 1\n",
        "\n",
        "            if len(context) > 0: context_arr.add(\" \".join(context))\n",
        "        datasets_detected.append({\"dmdd_id\": dmdd_id, \"new\": dataset, \"context\": list(context_arr)})"
      ],
      "metadata": {
        "id": "Ajkn1sdbGye-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d16404-d528-4859-8e63-08e48d6be019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "99it [00:08, 11.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exploded_df: pd.DataFrame = pd.DataFrame(datasets_detected).explode(\"context\")\n",
        "exploded_df[\"original\"] = exploded_df[\"dmdd_id\"].map(lambda x: \", \".join(y if (y:=df[\"ground\"][x]) != None else []) if len(\", \".join(y if (y:=df[\"ground\"][x]) != None else [])) > 0 else None)\n",
        "exploded_df[\"DR\"] = \"\"\n",
        "exploded_df[\"PD\"] = \"\"\n",
        "exploded_df[\"Source\"] = \"\"\n",
        "exploded_df = exploded_df.set_index(\n",
        "    [\n",
        "        \"dmdd_id\",\n",
        "        \"original\",\n",
        "        \"new\",\n",
        "        \"DR\",\n",
        "        \"PD\",\n",
        "        \"Source\",\n",
        "        exploded_df.groupby([\"new\"]).cumcount(),\n",
        "    ]\n",
        ")\n",
        "exploded_df.index.names = [\"DMDD ID\", \"Original\", \"New\", \"DR\", \"PD\", \"Source\", \"Passage No.\"]\n",
        "exploded_df.to_excel(\n",
        "    f\"./drive/MyDrive/Thesis/Dataset_Extraction/annotations/dmdd_modified/{id_range[0]}_{id_range[1] - 1}.xlsx\"\n",
        ")\n",
        "# exploded_df.isna()\n",
        "# exploded_df.isna().sum()"
      ],
      "metadata": {
        "id": "FI2nBVYGwdYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toRBDJoZcWxN"
      },
      "outputs": [],
      "source": [
        "# @title Format code\n",
        "!black ./drive/MyDrive/'Colab Notebooks'/'Baseline Presentation.ipynb'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for text in group_sentences(sentence_splitter(get_text(dmdd,1)), 20, 0):\n",
        "#     print(\"Burst\".lower() in text.lower())\n",
        "sentence_splitter(get_text(dmdd, 1))\n",
        "# for i, text in enumerate(group_sentences(sentences, 20, 0)):\n",
        "#     if \"Burst\" in text:\n",
        "#         print(i)"
      ],
      "metadata": {
        "id": "qJl3m-1mYq0L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}